{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a6e92-e174-45d1-b59a-7a200fd21851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,\\\n",
    "                             ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "# over-sampling techniques\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, \\\n",
    "                                   ADASYN, BorderlineSMOTE, \\\n",
    "                                   KMeansSMOTE, SVMSMOTE, \\\n",
    "                                   SMOTENC, SMOTEN\n",
    "\n",
    "# under-sampling techniques\n",
    "from imblearn.under_sampling import ClusterCentroids, RandomUnderSampler, \\\n",
    "                                    NearMiss, CondensedNearestNeighbour, \\\n",
    "                                    TomekLinks, EditedNearestNeighbours, \\\n",
    "                                    OneSidedSelection, NeighbourhoodCleaningRule\n",
    "\n",
    "\n",
    "from estimators import EstimatorSelectionHelper\n",
    "from graphics import generate_graphics_from_gridsearchcv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = '.config_ipynb'\n",
    "with open(CONFIG_FILE) as f:\n",
    "    sys.argv = f.read().split()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_path', default='', type=str, help='path of dataset')\n",
    "args, _ = parser.parse_known_args(sys.argv[1:])\n",
    "\n",
    "dataset_path = args.dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71126134-1da0-4841-b048-acb9ae38d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3dc54f-8a1c-46a8-a458-383723549911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_results_folder(dataset_name):\n",
    "\n",
    "    def __create_folder(folder_name):\n",
    "        if not os.path.exists(folder_name): \n",
    "            os.makedirs(folder_name)\n",
    "    \n",
    "    for f in [\n",
    "        results_dataset_folder := f'results/{dataset_name}/',\n",
    "       *[f'{results_dataset_folder}/{sf}' for sf in ['imgs', 'pkls', 'test_results']],\n",
    "    ]:\n",
    "        __create_folder(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfec3be-8c90-4be7-8c77-6b1581aad80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAY = datetime.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d3428-0c73-430c-b3c6-3ec0e8ed9ef3",
   "metadata": {},
   "source": [
    "### Criação das etapas de processamento\n",
    "\n",
    "- Algoritmos de pré-processamento\n",
    "- Parâmetros dos algoritmos de pré-processamento\n",
    "\n",
    "\n",
    "- Algoritmos de classificação\n",
    "- Parâmetros dos algoritmos de classificação\n",
    "\n",
    "\n",
    "- Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb8fe0-6512-405f-8223-1e76e40e6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pré-processamento\n",
    "transformers = {\n",
    "    None: None,\n",
    "    SMOTE(): {\n",
    "        'sampling_strategy': [0.5, 0.8, 1],\n",
    "        'k_neighbors': [3, 7, 9],\n",
    "    },\n",
    "    BorderlineSMOTE(): {\n",
    "        'sampling_strategy': [0.5, 0.8, 1],\n",
    "        'kind': ['borderline-1', 'borderline-2'],\n",
    "    },\n",
    "    ClusterCentroids(): {\n",
    "        'sampling_strategy': [0.5, 0.8, 1],        \n",
    "    },\n",
    "    NearMiss():{\n",
    "        'version': [1, 2],\n",
    "        'n_neighbors': [3, 7, 9],\n",
    "    }\n",
    "}\n",
    "\n",
    "# learning models\n",
    "models = {\n",
    "    ExtraTreesClassifier(): {\n",
    "        'n_estimators': [16, 32, 64, 128],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [8, 16, 32, None],\n",
    "    },\n",
    "    RandomForestClassifier(): {\n",
    "        'n_estimators': [16, 32, 64, 128],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [8, 16, 32, None],\n",
    "    },\n",
    "    DecisionTreeClassifier(): { \n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [8, 16, 32, None],\n",
    "    },\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\"): {\n",
    "        'n_estimators': [8, 16, 32, 64, 128],\n",
    "    },\n",
    "    GradientBoostingClassifier(): {\n",
    "        'n_estimators': [16, 32, 64, 128],\n",
    "        'learning_rate': [0.01, 0.1, 0.5, 0.8],\n",
    "    },\n",
    "    # SVC(): [\n",
    "    #     {'kernel': ['linear'], 'C': [1, 10]},\n",
    "    #     {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    # ],\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'AUPRC': 'average_precision',\n",
    "    'AUROC': 'roc_auc',\n",
    "    'f1': 'f1',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ce05e-5d82-4c2b-a14e-05f6ba6edd6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cell_to_latex(c):\n",
    "    if c in [None, '', {}]:\n",
    "        return ''\n",
    "\n",
    "    if isinstance(c, str):\n",
    "        c = json.loads(c)\n",
    "\n",
    "    return (\n",
    "        r'\\makecell[l]{' +\n",
    "        ' \\\\\\\\ '.join(\n",
    "            [f'{k} = {v}' for k, v in c.items()]\n",
    "        ) + \n",
    "        '}'\n",
    "    )\n",
    "\n",
    "def class_to_repr(c):\n",
    "    return c.__repr__()\n",
    "\n",
    "HIPER_PARAMS = 'Hiper-parâmetros'\n",
    "param_df = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        transformers | models,\n",
    "        orient='index',\n",
    "        columns=[HIPER_PARAMS]\n",
    "    )\n",
    "    .fillna('')\n",
    ").reset_index().rename(\n",
    "    columns={'index': 'Algoritmo'}\n",
    ")\n",
    "\n",
    "param_df['Algoritmo'] = param_df['Algoritmo'].apply(lambda x: x.__class__.__name__)\n",
    "param_df[HIPER_PARAMS] = param_df[HIPER_PARAMS].apply(cell_to_latex)\n",
    "param_df.to_csv('results/params_df.csv', sep='\\t')\n",
    "print(param_df.style.hide(axis='index').to_latex().replace('_', r'\\_'))\n",
    "param_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014443b6-1e55-4eff-b2a6-4ad167f47ae2",
   "metadata": {},
   "source": [
    "### Leitura e tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d25ba-e51c-496a-8f85-d09f1f2e70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_path.endswith('.arff'):\n",
    "\n",
    "    data = arff.loadarff(f'{dataset_path}')\n",
    "    df = pd.DataFrame(data[0])\n",
    "\n",
    "    # separa em atributos em variável X, e classe em variável y\n",
    "    x = df.drop('Class', axis=1)\n",
    "    y = df['Class'].astype(int)\n",
    "\n",
    "else:\n",
    "    df = pd.read_csv(f'{dataset_path}')\n",
    "\n",
    "    # separa em atributos em variável X, e classe em variável y\n",
    "    # dropa variavel de tempo\n",
    "    x = df.drop(['Class', 'Time'], axis=1)\n",
    "    y = df['Class']\n",
    "\n",
    "dataset_name = os.path.splitext(os.path.basename(dataset_path))[0]\n",
    "create_dataset_results_folder(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8c64d-4ef5-4da4-aa1f-0bc6177c5d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para testes, limitar a quantidade de dados aumentando test_size...\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y,\n",
    "    stratify=y,\n",
    "    test_size=0.15\n",
    ")\n",
    "\n",
    "helper = EstimatorSelectionHelper(\n",
    "    transformers,\n",
    "    models, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af76add2",
   "metadata": {},
   "source": [
    "### Fitting the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_initial = datetime.now()\n",
    "\n",
    "stratified_kfold = StratifiedKFold(\n",
    "    n_splits=5,\n",
    ")\n",
    "helper.fit_predict(\n",
    "    x, y,\n",
    "    scoring=scoring, cv=stratified_kfold, \n",
    "    n_jobs=5, \n",
    "    refit='AUPRC', \n",
    "    verbose=2,\n",
    "    dataset_name=dataset_name\n",
    ")\n",
    "\n",
    "metadata_summary = helper.generate_metadata_summary()\n",
    "metadata_summary.to_csv(f'results/{dataset_name}/metadata_summary.txt', sep='\\t')\n",
    "\n",
    "estimators = pd.unique(metadata_summary.index.unique(level='estimator'))\n",
    "map_estimators = dict(zip(estimators, [chr(ord('a') + i) for i, x in enumerate(estimators)]))\n",
    "\n",
    "score_summary = helper.generate_score_summary()\n",
    "score_summary['Caractere'] = score_summary.estimator.map(map_estimators)\n",
    "score_summary \\\n",
    "    .sort_values(by='mean_test_AUPRC_score', ascending=False) \\\n",
    "    .to_csv(f'results/{dataset_name}/score_summary.txt', sep='\\t', index=False)\n",
    "# score_summary.to_csv(f'results/{dataset_name}/score_summary.txt', sep='\\t')\n",
    "\n",
    "t_final = datetime.now()\n",
    "\n",
    "# get difference\n",
    "delta = t_final - t_initial\n",
    "\n",
    "# time difference in seconds\n",
    "now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f'[{now}] Total execution time is {delta} ({delta.total_seconds()} seconds).')\n",
    "\n",
    "generate_graphics_from_gridsearchcv_results(\n",
    "    dataset_name,\n",
    "    score_summary,\n",
    "    scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3a892-81fc-4883-9701-343233db48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_summary.index.names = ['estimator', 'n']\n",
    "metadata_summary.reset_index(inplace=True)\n",
    "metadata_summary['Caractere'] = metadata_summary.estimator.map(map_estimators)\n",
    "metadata_summary.set_index(['estimator', 'n'], inplace=True)\n",
    "\n",
    "metadata_summary.head()\n",
    "\n",
    "tabela_estimadores = pd.Series(map_estimators).to_frame('Caractere')\n",
    "tabela_estimadores.index.name = 'Estimador'\n",
    "tabela_estimadores.reset_index(inplace=True)\n",
    "\n",
    "print(tabela_estimadores.style.hide(axis=\"index\").to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

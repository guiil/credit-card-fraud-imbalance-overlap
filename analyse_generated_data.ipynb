{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_NUMERIC, \"pt_BR\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    'axes.formatter.use_locale': True,\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context(\"paper\", font_scale = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = 'results/'\n",
    "samples = 3000\n",
    "class_ratios = [\n",
    "    '1to2.5', '1to3', '1to4', '1to5', '1to6', \n",
    "    '1to7', '1to8', '1to9', '1to10', '1to20'\n",
    "]\n",
    "class_1_radius = [f'{i/10}, {i/10}' for i in range(1, 6, 1)]\n",
    "\n",
    "distances = ['1_2', '0_8', '0_4', '0_0']\n",
    "\n",
    "total_ratios = len(class_ratios)\n",
    "total_radius = len(class_1_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Média de desempenhos de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(\n",
    "    figsize=(6.29707, 8),\n",
    ")\n",
    "\n",
    "fig.suptitle(\n",
    "    (\n",
    "        f'Médias dos desempenhos por $D$, $R_{{min}}$ e $IR$, onde $N = {samples}$'\n",
    "    ),\n",
    "    y=1.04\n",
    ")\n",
    "\n",
    "subfigs = fig.subfigures(\n",
    "    nrows=total_ratios,\n",
    "    ncols=1,\n",
    ")\n",
    "\n",
    "for i_ratios, ratio in enumerate(class_ratios):\n",
    "    ratio_str = ratio.split('to')[1].replace('.', ',')\n",
    "    subfigs[i_ratios].suptitle(f'$IR = {ratio_str}$', y=1.05, fontsize=10)\n",
    "    axs = subfigs[i_ratios].subplots(\n",
    "        nrows=1,\n",
    "        ncols=total_radius,\n",
    "    )\n",
    "\n",
    "    for i_radius, radius in enumerate(class_1_radius):\n",
    "        radius_str = radius[:3]\n",
    "        radius_filename = radius_str.replace('.', '_')\n",
    "        \n",
    "        plot_df = pd.DataFrame()\n",
    "        for distance in distances:\n",
    "            distance_str = distance.replace('_', '.')\n",
    "\n",
    "            results_path = f'results/spheres-2d-samples={samples}-radius={radius_filename}-ratio={ratio}-distance={distance}/'\n",
    "\n",
    "            test_results_path = glob.glob(f'{results_path}/test_results/*.json')\n",
    "            test_df = pd.DataFrame()\n",
    "            for file in test_results_path:\n",
    "                estimator_name = file[:-5].replace('__', ' | ')\n",
    "                with open(file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                estimator_test_df = pd.json_normalize(data)\n",
    "                estimator_test_df['estimator'] = estimator_name\n",
    "                estimator_test_df = estimator_test_df[['estimator', 'auprc', 'roc_auc', 'f1-score']]\n",
    "                test_df = pd.concat([test_df, estimator_test_df])\n",
    "\n",
    "            mean_test_AUPRC_score = test_df.loc[\n",
    "                :,\n",
    "                'auprc'\n",
    "            ].mean()\n",
    "            mean_test_AUROC_score = test_df.loc[\n",
    "                :,\n",
    "                'roc_auc'\n",
    "            ].mean()\n",
    "            mean_test_f1_score = test_df.loc[\n",
    "                :,\n",
    "                'f1-score'\n",
    "            ].mean()\n",
    "\n",
    "            plot_df = pd.concat(\n",
    "                [\n",
    "                    plot_df,\n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                            'AUPRC': mean_test_AUPRC_score,\n",
    "                            'AUROC': mean_test_AUROC_score,\n",
    "                            'f1': mean_test_f1_score\n",
    "                        }, index=[float(distance_str)]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        lineplt = sns.lineplot(\n",
    "            plot_df,\n",
    "            legend=True,\n",
    "            ax=axs[i_radius],\n",
    "        )\n",
    "        axs[i_radius].set_xlim(0, 1.2)\n",
    "        axs[i_radius].set_ylim(0, 1)\n",
    "\n",
    "        axs[i_radius].set(xlabel=None, ylabel=None)\n",
    "        radius_str = radius_str.replace('.', ',')\n",
    "        axs[i_radius].text(0.36, 0.05, f'$R_{{min}} = {radius_str}$', fontsize=7)                \n",
    "\n",
    "        axs[i_radius].tick_params(axis='both', which='major', labelsize=7)\n",
    "\n",
    "        if i_radius == 0:\n",
    "            axs[i_radius].set_xticks([0, 0.5, 1])\n",
    "\n",
    "        if i_radius == 0 and i_ratios == 4:\n",
    "            axs[i_radius].set(ylabel='Desempenho')\n",
    "\n",
    "        if i_radius != 0:\n",
    "            axs[i_radius].set_yticks([])           \n",
    "\n",
    "        if i_ratios == total_ratios - 1 and i_radius == 2:\n",
    "            axs[i_radius].set(xlabel='D')  \n",
    "\n",
    "        if i_ratios == total_ratios - 1:\n",
    "            axs[i_radius].set_xticks([1.2, 0.8, 0.4, 0.0])\n",
    "        \n",
    "        if i_ratios != total_ratios - 1:\n",
    "            axs[i_radius].set_xticks([])\n",
    "\n",
    "        lineplt.get_legend().remove()\n",
    "        if i_ratios == total_ratios - 1 and i_radius == total_radius - 1:\n",
    "            lineplt.legend(loc='lower center', bbox_to_anchor=(-2, -1.4), ncol=3)\n",
    "            L = lineplt.get_legend()\n",
    "            L.get_texts()[0].set_text('$\\\\overline{{AUPRC(E_{\\\\kappa}(\\\\tau))}}$')\n",
    "            L.get_texts()[1].set_text('$\\\\overline{{AUROC(E_{\\\\kappa}(\\\\tau))}}$')\n",
    "            L.get_texts()[2].set_text('$\\\\overline{{f_{1}(E_{\\\\kappa}(\\\\tau)}}$')\n",
    "plt.savefig(\n",
    "    f'results/samples={samples}_generated_data_performance.pgf',\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    f'results/samples={samples}_generated_data_performance.png',\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Comparação geral do uso de pré-processamento de amostragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(\n",
    "    figsize=(6.29707, 8),\n",
    ")\n",
    "\n",
    "fig.suptitle(\n",
    "    (\n",
    "        'Diferenças nas médias de desempenho entre amostragem e não-amostragem\\n'\n",
    "        f'por $D$ e $IR$, para $N = {samples}$'\n",
    "    ),\n",
    "    y=1.06\n",
    ")\n",
    "\n",
    "subfigs = fig.subfigures(\n",
    "    nrows=total_ratios,\n",
    "    ncols=1,\n",
    ")\n",
    "\n",
    "for i_ratios, ratio in enumerate(class_ratios):\n",
    "    ratio_str = ratio.split('to')[1]\n",
    "    subfigs[i_ratios].suptitle(f'$IR = {ratio_str}$', y=1.05, fontsize=10)\n",
    "    axs = subfigs[i_ratios].subplots(\n",
    "        nrows=1,\n",
    "        ncols=total_radius,\n",
    "    )\n",
    "\n",
    "    for i_radius, radius in enumerate(class_1_radius):\n",
    "        radius_str = radius[:3]\n",
    "        radius_filename = radius_str.replace('.', '_')\n",
    "        \n",
    "        plot_df = pd.DataFrame()\n",
    "        for distance in distances:\n",
    "            distance_str = distance.replace('_', '.')\n",
    "\n",
    "            results_path = f'results/spheres-2d-samples={samples}-radius={radius_filename}-ratio={ratio}-distance={distance}/'\n",
    "            test_results_path = glob.glob(f'{results_path}/test_results/*.json')\n",
    "            test_df = pd.DataFrame()\n",
    "            for file_path in test_results_path:\n",
    "                file_name = os.path.basename(file_path)\n",
    "                estimator_name = file_name[:-5].replace('__', ' | ')\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                estimator_test_df = pd.json_normalize(data)\n",
    "                estimator_test_df['estimator'] = estimator_name\n",
    "                estimator_test_df = estimator_test_df[['estimator', 'auprc', 'roc_auc', 'f1-score']]\n",
    "                test_df = pd.concat([test_df, estimator_test_df])\n",
    "\n",
    "            # NO SAMPLING\n",
    "            baseline_mean_test_AUPRC_score = test_df.loc[\n",
    "                ~test_df['estimator'].str.contains('|', regex=False),\n",
    "                'auprc'\n",
    "            ].mean()\n",
    "            baseline_mean_test_AUROC_score = test_df.loc[\n",
    "                ~test_df['estimator'].str.contains('|', regex=False),\n",
    "                'roc_auc'\n",
    "            ].mean()\n",
    "            baseline_mean_test_f1_score = test_df.loc[\n",
    "                ~test_df['estimator'].str.contains('|', regex=False),\n",
    "                'f1-score'\n",
    "            ].mean()\n",
    "\n",
    "            # SMOTE\n",
    "            smote_mean_test_AUPRC_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('SMOTE'),\n",
    "                'auprc'\n",
    "            ].mean()\n",
    "            smote_mean_test_AUROC_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('SMOTE'),\n",
    "                'roc_auc'\n",
    "            ].mean()\n",
    "            smote_mean_test_f1_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('SMOTE'),\n",
    "                'f1-score'\n",
    "            ].mean()\n",
    "\n",
    "            # BORDERLINE SMOTE\n",
    "            borderlinesmote_mean_test_AUPRC_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('BorderlineSMOTE'),\n",
    "                'auprc'\n",
    "            ].mean()\n",
    "            borderlinesmote_mean_test_AUROC_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('BorderlineSMOTE'),\n",
    "                'roc_auc'\n",
    "            ].mean()\n",
    "            borderlinesmote_mean_test_f1_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('BorderlineSMOTE'),\n",
    "                'f1-score'\n",
    "            ].mean()\n",
    "\n",
    "            # CLUSTER CENTROIDS\n",
    "            clustercentroids_mean_test_AUPRC_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('ClusterCentroids'),\n",
    "                'auprc'\n",
    "            ].mean()\n",
    "            clustercentroids_mean_test_AUROC_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('ClusterCentroids'),\n",
    "                'roc_auc'\n",
    "            ].mean()\n",
    "            clustercentroids_mean_test_f1_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('ClusterCentroids'),\n",
    "                'f1-score'\n",
    "            ].mean()\n",
    "\n",
    "            # NEAR MISS\n",
    "            nearmiss_mean_test_AUPRC_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('NearMiss'),\n",
    "                'auprc'\n",
    "            ].mean()\n",
    "            nearmiss_mean_test_AUROC_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('NearMiss'),\n",
    "                'roc_auc'\n",
    "            ].mean()\n",
    "            nearmiss_mean_test_f1_score = test_df.loc[\n",
    "                test_df['estimator'].str.startswith('NearMiss'),\n",
    "                'f1-score'\n",
    "            ].mean()\n",
    "\n",
    "            smote_delta_auprc = smote_mean_test_AUPRC_score - baseline_mean_test_AUPRC_score\n",
    "            borderlinesmote_delta_auprc = borderlinesmote_mean_test_AUPRC_score - baseline_mean_test_AUPRC_score\n",
    "            clustercentroids_delta_auprc = clustercentroids_mean_test_AUPRC_score - baseline_mean_test_AUPRC_score\n",
    "            nearmiss_delta_auprc = nearmiss_mean_test_AUPRC_score - baseline_mean_test_AUPRC_score\n",
    "\n",
    "            plot_df = pd.concat(\n",
    "                [\n",
    "                    plot_df,\n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                            'SMOTE': smote_delta_auprc,\n",
    "                            'BorderlineSMOTE': borderlinesmote_delta_auprc,\n",
    "                            'ClusterCentroids': clustercentroids_delta_auprc,\n",
    "                            'NearMiss': nearmiss_delta_auprc\n",
    "                        }, index=[float(distance_str)]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        lineplt = sns.lineplot(\n",
    "            plot_df,\n",
    "            legend=True,\n",
    "            ax=axs[i_radius],\n",
    "        )\n",
    "        axs[i_radius].set_xlim(0, 1.2)\n",
    "        axs[i_radius].set_ylim(-.5, .5)\n",
    "\n",
    "        axs[i_radius].set(xlabel=None, ylabel=None)\n",
    "        radius_str = radius_str.replace('.', ',')\n",
    "        axs[i_radius].text(0.04, 0.36, f'$R_{{min}} = {radius_str}$', fontsize=7)\n",
    "\n",
    "        axs[i_radius].tick_params(axis='both', which='major', labelsize=7)\n",
    "\n",
    "        if i_radius == 0:\n",
    "            axs[i_radius].set_xticks([0, 0.5, 1])\n",
    "\n",
    "        if i_radius == 0 and i_ratios == 4:\n",
    "            axs[i_radius].set(ylabel='Diferença no desempenho')\n",
    "\n",
    "        if i_radius != 0:\n",
    "            axs[i_radius].set_yticks([])           \n",
    "\n",
    "        if i_ratios == total_ratios - 1 and i_radius == 2:\n",
    "            axs[i_radius].set(xlabel='$D$')  \n",
    "\n",
    "        if i_ratios == total_ratios - 1:\n",
    "            axs[i_radius].set_xticks([1.2, 0.8, 0.4, 0.0])\n",
    "        \n",
    "        if i_ratios != total_ratios - 1:\n",
    "            axs[i_radius].set_xticks([])\n",
    "\n",
    "        lineplt.get_legend().remove()\n",
    "        if i_ratios == total_ratios - 1 and i_radius == total_radius - 1:\n",
    "            lineplt.legend(title='$\\\\Delta AUPRC_{{amost.}}$', loc='lower center', bbox_to_anchor=(-2, -2), ncol=2)\n",
    "\n",
    "plt.savefig(\n",
    "    f'results/samples={samples}_generated_data_delta_performance.pgf',\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    f'results/samples={samples}_generated_data_delta_performance.png',\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Desempenhos por grupo estimador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    'ExtraTreesClassifier',\n",
    "    'RandomForestClassifier',\n",
    "    'DecisionTreeClassifier',\n",
    "    'AdaBoostClassifier',\n",
    "    'GradientBoostingClassifier'\n",
    "]\n",
    "\n",
    "\n",
    "for e in estimators:\n",
    "    fig = plt.figure(\n",
    "        figsize=(6.29707, 8),\n",
    "    )\n",
    "\n",
    "    fig.suptitle(\n",
    "        (\n",
    "            f'Médias dos desempenhos para o estimador {e}\\n'\n",
    "            f'por $D$, $R_{{min}}$ e $IR$, onde $N = {samples}$'\n",
    "        ),\n",
    "        y=1.06\n",
    "    )\n",
    "\n",
    "    subfigs = fig.subfigures(\n",
    "        nrows=total_ratios,\n",
    "        ncols=1,\n",
    "    )\n",
    "\n",
    "    for i_ratios, ratio in enumerate(class_ratios):\n",
    "        ratio_str = ratio.split('to')[1].replace('.', ',')\n",
    "        subfigs[i_ratios].suptitle(f'$IR = {ratio_str}$', y=1.05, fontsize=10)\n",
    "        axs = subfigs[i_ratios].subplots(\n",
    "            nrows=1,\n",
    "            ncols=total_radius,\n",
    "        )\n",
    "\n",
    "        for i_radius, radius in enumerate(class_1_radius):\n",
    "            radius_str = radius[:3]\n",
    "            radius_filename = radius_str.replace('.', '_')\n",
    "            \n",
    "            plot_df = pd.DataFrame()\n",
    "            for distance in distances:\n",
    "                distance_str = distance.replace('_', '.')\n",
    "\n",
    "                results_path = f'results/spheres-2d-samples={samples}-radius={radius_filename}-ratio={ratio}-distance={distance}/'\n",
    "\n",
    "                test_results_path = glob.glob(f'{results_path}/test_results/*.json')\n",
    "                test_df = pd.DataFrame()\n",
    "                for file in test_results_path:\n",
    "                    estimator_name = file[:-5].replace('__', ' | ')\n",
    "                    with open(file, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    estimator_test_df = pd.json_normalize(data)\n",
    "                    estimator_test_df['estimator'] = estimator_name\n",
    "                    estimator_test_df = estimator_test_df[['estimator', 'auprc', 'roc_auc', 'f1-score']]\n",
    "                    test_df = pd.concat([test_df, estimator_test_df])\n",
    "\n",
    "                mean_test_AUPRC_score = test_df.loc[\n",
    "                    test_df['estimator'].str.contains(e),\n",
    "                    'auprc'\n",
    "                ].mean()\n",
    "                mean_test_AUROC_score = test_df.loc[\n",
    "                    test_df['estimator'].str.contains(e),\n",
    "                    'roc_auc'\n",
    "                ].mean()\n",
    "                mean_test_f1_score = test_df.loc[\n",
    "                    test_df['estimator'].str.contains(e),\n",
    "                    'f1-score'\n",
    "                ].mean()\n",
    "\n",
    "                plot_df = pd.concat(\n",
    "                    [\n",
    "                        plot_df,\n",
    "                        pd.DataFrame(\n",
    "                            {\n",
    "                                'AUPRC': mean_test_AUPRC_score,\n",
    "                                'AUROC': mean_test_AUROC_score,\n",
    "                                'f1': mean_test_f1_score\n",
    "                            }, index=[float(distance_str)]\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            lineplt = sns.lineplot(\n",
    "                plot_df,\n",
    "                legend=True,\n",
    "                ax=axs[i_radius],\n",
    "            )\n",
    "            axs[i_radius].set_xlim(0, 1.2)\n",
    "            axs[i_radius].set_ylim(0, 1)\n",
    "\n",
    "            axs[i_radius].set(xlabel=None, ylabel=None)\n",
    "            radius_str = radius_str.replace('.', ',')\n",
    "            axs[i_radius].text(0.36, 0.05, f'$R_{{min}} = {radius_str}$', fontsize=7)                \n",
    "\n",
    "            axs[i_radius].tick_params(axis='both', which='major', labelsize=7)\n",
    "\n",
    "            if i_radius == 0:\n",
    "                axs[i_radius].set_xticks([0, 0.5, 1])\n",
    "\n",
    "            if i_radius == 0 and i_ratios == 4:\n",
    "                axs[i_radius].set(ylabel='Desempenho')\n",
    "\n",
    "            if i_radius != 0:\n",
    "                axs[i_radius].set_yticks([])           \n",
    "\n",
    "            if i_ratios == total_ratios - 1 and i_radius == 2:\n",
    "                axs[i_radius].set(xlabel='D')  \n",
    "\n",
    "            if i_ratios == total_ratios - 1:\n",
    "                axs[i_radius].set_xticks([1.2, 0.8, 0.4, 0.0])\n",
    "            \n",
    "            if i_ratios != total_ratios - 1:\n",
    "                axs[i_radius].set_xticks([])\n",
    "\n",
    "            lineplt.get_legend().remove()\n",
    "            if i_ratios == total_ratios - 1 and i_radius == total_radius - 1:\n",
    "                lineplt.legend(loc='lower center', bbox_to_anchor=(-2, -1.4), ncol=3)\n",
    "                L = lineplt.get_legend()\n",
    "                L.get_texts()[0].set_text('$\\\\overline{{AUPRC(E_{\\\\kappa}(\\\\tau))}}$')\n",
    "                L.get_texts()[1].set_text('$\\\\overline{{AUROC(E_{\\\\kappa}(\\\\tau))}}$')\n",
    "                L.get_texts()[2].set_text('$\\\\overline{{f_{1}(E_{\\\\kappa}(\\\\tau))}}$')\n",
    "    plt.savefig(\n",
    "        f'results/samples={samples}-estimator={e}_generated_data_performance.pgf',\n",
    "        bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.savefig(\n",
    "        f'results/samples={samples}-estimator={e}_generated_data_performance.png',\n",
    "        bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    'ExtraTreesClassifier',\n",
    "    'RandomForestClassifier',\n",
    "    'DecisionTreeClassifier',\n",
    "    'AdaBoostClassifier',\n",
    "    'GradientBoostingClassifier'\n",
    "]\n",
    "\n",
    "\n",
    "for e in estimators:\n",
    "    fig = plt.figure(\n",
    "        figsize=(6.29707, 8),\n",
    "    )\n",
    "\n",
    "    fig.suptitle(\n",
    "        (\n",
    "            'Diferenças nas médias de desempenho entre amostragem e não-amostragem\\n'\n",
    "            f'para o estimador {e} por $D$ e $IR$, para $N = {samples}$'\n",
    "        ),\n",
    "        y=1.06\n",
    "    )\n",
    "\n",
    "    subfigs = fig.subfigures(\n",
    "        nrows=total_ratios,\n",
    "        ncols=1,\n",
    "    )\n",
    "\n",
    "    for i_ratios, ratio in enumerate(class_ratios):\n",
    "        ratio_str = ratio.split('to')[1].replace('.', ',')\n",
    "        subfigs[i_ratios].suptitle(f'$IR = {ratio_str}$', y=1.05, fontsize=10)\n",
    "        axs = subfigs[i_ratios].subplots(\n",
    "            nrows=1,\n",
    "            ncols=total_radius,\n",
    "        )\n",
    "\n",
    "        for i_radius, radius in enumerate(class_1_radius):\n",
    "            radius_str = radius[:3]\n",
    "            radius_filename = radius_str.replace('.', '_')\n",
    "            \n",
    "            plot_df = pd.DataFrame()\n",
    "            for distance in distances:\n",
    "                distance_str = distance.replace('_', '.')\n",
    "\n",
    "                results_path = f'results/spheres-2d-samples={samples}-radius={radius_filename}-ratio={ratio}-distance={distance}/'\n",
    "                test_results_path = glob.glob(f'{results_path}/test_results/*.json')\n",
    "                test_df = pd.DataFrame()\n",
    "                for file_path in test_results_path:\n",
    "                    file_name = os.path.basename(file_path)\n",
    "                    estimator_name = file_name[:-5].replace('__', ' | ')\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    estimator_test_df = pd.json_normalize(data)\n",
    "                    estimator_test_df['estimator'] = estimator_name\n",
    "                    estimator_test_df = estimator_test_df[['estimator', 'auprc', 'roc_auc', 'f1-score']]\n",
    "                    test_df = pd.concat([test_df, estimator_test_df])\n",
    "\n",
    "                test_df = test_df.loc[\n",
    "                    test_df['estimator'].str.contains(e),\n",
    "                    :\n",
    "                ]\n",
    "\n",
    "                # NO SAMPLING\n",
    "                baseline_mean_test_AUPRC_score = test_df.loc[\n",
    "                    ~test_df['estimator'].str.contains('|', regex=False),\n",
    "                    'auprc'\n",
    "                ].mean()\n",
    "                baseline_mean_test_AUROC_score = test_df.loc[\n",
    "                    ~test_df['estimator'].str.contains('|', regex=False),\n",
    "                    'roc_auc'\n",
    "                ].mean()\n",
    "                baseline_mean_test_f1_score = test_df.loc[\n",
    "                    ~test_df['estimator'].str.contains('|', regex=False),\n",
    "                    'f1-score'\n",
    "                ].mean()\n",
    "\n",
    "                # SMOTE\n",
    "                smote_mean_test_AUPRC_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('SMOTE'),\n",
    "                    'auprc'\n",
    "                ].mean()\n",
    "                smote_mean_test_AUROC_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('SMOTE'),\n",
    "                    'roc_auc'\n",
    "                ].mean()\n",
    "                smote_mean_test_f1_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('SMOTE'),\n",
    "                    'f1-score'\n",
    "                ].mean()\n",
    "\n",
    "                # BORDERLINE SMOTE\n",
    "                borderlinesmote_mean_test_AUPRC_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('BorderlineSMOTE'),\n",
    "                    'auprc'\n",
    "                ].mean()\n",
    "                borderlinesmote_mean_test_AUROC_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('BorderlineSMOTE'),\n",
    "                    'roc_auc'\n",
    "                ].mean()\n",
    "                borderlinesmote_mean_test_f1_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('BorderlineSMOTE'),\n",
    "                    'f1-score'\n",
    "                ].mean()\n",
    "\n",
    "                # CLUSTER CENTROIDS\n",
    "                clustercentroids_mean_test_AUPRC_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('ClusterCentroids'),\n",
    "                    'auprc'\n",
    "                ].mean()\n",
    "                clustercentroids_mean_test_AUROC_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('ClusterCentroids'),\n",
    "                    'roc_auc'\n",
    "                ].mean()\n",
    "                clustercentroids_mean_test_f1_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('ClusterCentroids'),\n",
    "                    'f1-score'\n",
    "                ].mean()\n",
    "\n",
    "                # NEAR MISS\n",
    "                nearmiss_mean_test_AUPRC_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('NearMiss'),\n",
    "                    'auprc'\n",
    "                ].mean()\n",
    "                nearmiss_mean_test_AUROC_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('NearMiss'),\n",
    "                    'roc_auc'\n",
    "                ].mean()\n",
    "                nearmiss_mean_test_f1_score = test_df.loc[\n",
    "                    test_df['estimator'].str.startswith('NearMiss'),\n",
    "                    'f1-score'\n",
    "                ].mean()\n",
    "\n",
    "                smote_delta_auprc = smote_mean_test_AUPRC_score - baseline_mean_test_AUPRC_score\n",
    "                borderlinesmote_delta_auprc = borderlinesmote_mean_test_AUPRC_score - baseline_mean_test_AUPRC_score\n",
    "                clustercentroids_delta_auprc = clustercentroids_mean_test_AUPRC_score - baseline_mean_test_AUPRC_score\n",
    "                nearmiss_delta_auprc = nearmiss_mean_test_AUPRC_score - baseline_mean_test_AUPRC_score\n",
    "\n",
    "                plot_df = pd.concat(\n",
    "                    [\n",
    "                        plot_df,\n",
    "                        pd.DataFrame(\n",
    "                            {\n",
    "                                'SMOTE': smote_delta_auprc,\n",
    "                                'BorderlineSMOTE': borderlinesmote_delta_auprc,\n",
    "                                'ClusterCentroids': clustercentroids_delta_auprc,\n",
    "                                'NearMiss': nearmiss_delta_auprc\n",
    "                            }, index=[float(distance_str)]\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            lineplt = sns.lineplot(\n",
    "                plot_df,\n",
    "                legend=True,\n",
    "                ax=axs[i_radius],\n",
    "            )\n",
    "            axs[i_radius].set_xlim(0, 1.2)\n",
    "            axs[i_radius].set_ylim(-.5, .5)\n",
    "\n",
    "            axs[i_radius].set(xlabel=None, ylabel=None)\n",
    "            radius_str = radius_str.replace('.', ',')\n",
    "            axs[i_radius].text(0.04, 0.36, f'$R_{{min}} = {radius_str}$', fontsize=7)\n",
    "\n",
    "            axs[i_radius].tick_params(axis='both', which='major', labelsize=7)\n",
    "\n",
    "            if i_radius == 0:\n",
    "                axs[i_radius].set_xticks([0, 0.5, 1])\n",
    "\n",
    "            if i_radius == 0 and i_ratios == 4:\n",
    "                axs[i_radius].set(ylabel='Diferença no desempenho')\n",
    "\n",
    "            if i_radius != 0:\n",
    "                axs[i_radius].set_yticks([])           \n",
    "\n",
    "            if i_ratios == total_ratios - 1 and i_radius == 2:\n",
    "                axs[i_radius].set(xlabel='$D$')  \n",
    "\n",
    "            if i_ratios == total_ratios - 1:\n",
    "                axs[i_radius].set_xticks([1.2, 0.8, 0.4, 0.0])\n",
    "            \n",
    "            if i_ratios != total_ratios - 1:\n",
    "                axs[i_radius].set_xticks([])\n",
    "\n",
    "            lineplt.get_legend().remove()\n",
    "            if i_ratios == total_ratios - 1 and i_radius == total_radius - 1:\n",
    "                lineplt.legend(title='$\\\\Delta AUPRC_{{amost.}}$', loc='lower center', bbox_to_anchor=(-2, -2), ncol=2)\n",
    "\n",
    "    plt.savefig(\n",
    "        f'results/samples={samples}-estimator={e}_generated_data_delta_performance.pgf',\n",
    "        bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.savefig(\n",
    "        f'results/samples={samples}-estimator={e}_generated_data_delta_performance.png',\n",
    "        bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
